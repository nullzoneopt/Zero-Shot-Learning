{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AWA2(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        classes_file,\n",
    "        transform=None,\n",
    "        path_prefix=\"data\",\n",
    "        predicate_binary_mask=True,\n",
    "    ):\n",
    "        self.transform = transform\n",
    "\n",
    "        if predicate_binary_mask:\n",
    "            self.predicates_mat = np.genfromtxt(\n",
    "                os.path.join(path_prefix, \"predicate-matrix-binary.txt\"), dtype=\"float\"\n",
    "            )\n",
    "        else:\n",
    "            self.predicates_mat = np.genfromtxt(\n",
    "                os.path.join(path_prefix, \"predicate-matrix-continuous.txt\"),\n",
    "                dtype=\"float\",\n",
    "            )\n",
    "\n",
    "        self.classes_dict = {}\n",
    "        classes_array = np.genfromtxt(\n",
    "            os.path.join(path_prefix, \"classes.txt\"), dtype=\"str\"\n",
    "        )\n",
    "        for row in classes_array:\n",
    "            self.classes_dict[row[1]] = int(row[0]) - 1\n",
    "        image_names = []\n",
    "        image_class_index = []\n",
    "\n",
    "        self.classes = []\n",
    "        with open(os.path.join(path_prefix, classes_file)) as f:\n",
    "            for line in f:\n",
    "                class_name = line.strip()\n",
    "                self.classes.append(class_name)\n",
    "                images = glob(\n",
    "                    os.path.join(path_prefix, \"JPEGImages\", class_name, \"*.jpg\")\n",
    "                )\n",
    "\n",
    "                class_index = self.classes_dict[class_name]\n",
    "                for image in images:\n",
    "                    image_names.append(image)\n",
    "                    image_class_index.append(class_index)\n",
    "\n",
    "        self.image_names = image_names\n",
    "        self.image_class_index = image_class_index\n",
    "        self.len = len(self.image_names)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.image_names[index])\n",
    "        #         print(image.shape)\n",
    "        if image.getbands()[0] == \"L\":\n",
    "            image = image.convert(\"RGB\")\n",
    "        #         if image.shape != (3,224,224):\n",
    "        #             print(self.image_class_index[index])\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        class_index = self.image_class_index[index]\n",
    "        image_predicate = self.predicates_mat[class_index, :]\n",
    "        return image, class_index, self.image_names[index], image_predicate\n",
    "\n",
    "    def display_sample(self, n=1):\n",
    "        for i in range(n):\n",
    "            plt.imshow(self.__getitem__(i)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transformers = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(brightness=0.3, contrast=0.3),\n",
    "        transforms.Resize((224, 224)),  # ImageNet standard\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_transformers = transforms.Compose(\n",
    "    [transforms.Resize((224, 224)), transforms.ToTensor()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = AWA2(\n",
    "    classes_file=\"testclasses.txt\", path_prefix=\"data1\", transform=train_transformers\n",
    ")\n",
    "train_dataset = AWA2(\n",
    "    classes_file=\"trainclasses.txt\", path_prefix=\"data1\", transform=test_transformers\n",
    ")\n",
    "len(train_dataset.classes), len(test_dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {\"batch_size\": 24, \"shuffle\": True, \"num_workers\": 0}\n",
    "test_params = {\"batch_size\": 1, \"shuffle\": True, \"num_workers\": 0}\n",
    "train_loader = DataLoader(train_dataset, **train_params)\n",
    "test_loader = DataLoader(test_dataset, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50, 85), 50, 50, 40)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predicates_ground_truth(\n",
    "    path_prefix=\"data\", predicate_binary_mask=True, train_classes=\"trainclasses.txt\"\n",
    "):\n",
    "    predicates_mat = None\n",
    "    if predicate_binary_mask:\n",
    "        predicates_mat = np.genfromtxt(\n",
    "            os.path.join(path_prefix, \"predicate-matrix-binary.txt\"), dtype=\"float\"\n",
    "        )\n",
    "    else:\n",
    "        predicates_mat = np.genfromtxt(\n",
    "            os.path.join(path_prefix, \"predicate-matrix-continuous.txt\"), dtype=\"float\",\n",
    "        )\n",
    "    classes_array = np.genfromtxt(\n",
    "        os.path.join(path_prefix, \"classes.txt\"), dtype=\"str\"\n",
    "    )[:, -1]\n",
    "    train_classes = np.genfromtxt(os.path.join(path_prefix, train_classes), dtype=\"str\")\n",
    "    return predicates_mat, len(predicates_mat), classes_array, train_classes\n",
    "\n",
    "\n",
    "predicates, num_predicates, classes, train_classes = predicates_ground_truth(\n",
    "    path_prefix=\"data1\"\n",
    ")\n",
    "predicates.shape, num_predicates, len(classes), len(train_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(is_pretrained=True, resnet=\"resnet34\", num_predicates=85):\n",
    "    model = None\n",
    "    if resnet == \"resnet18\":\n",
    "        model = torchvision.models.resnet18(pretrained=is_pretrained)\n",
    "    elif resnet == \"resnet50\":\n",
    "        model = torchvision.models.resnet50(pretrained=is_pretrained)\n",
    "    else:\n",
    "        model = torchvision.models.resnet34(pretrained=is_pretrained)\n",
    "    if is_pretrained:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.BatchNorm1d(num_features),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.25),\n",
    "        nn.Linear(num_features, num_predicates),\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Sequential(\n",
       "   (0): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (1): ReLU()\n",
       "   (2): Dropout(p=0.25, inplace=False)\n",
       "   (3): Linear(in_features=512, out_features=85, bias=True)\n",
       " ),\n",
       " True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model().to(device)\n",
    "model.fc, next(model.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COPIED CONTENT\n",
    "def cos_loss(input, target):\n",
    "    return 1 - F.cosine_similarity(input, target).mean()\n",
    "\n",
    "\n",
    "class AverageBase(object):\n",
    "    def __init__(self, value=0):\n",
    "        self.value = float(value) if value is not None else None\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(round(self.value, 4))\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.value\n",
    "\n",
    "    def __format__(self, fmt):\n",
    "        return self.value.__format__(fmt)\n",
    "\n",
    "    def __float__(self):\n",
    "        return self.value\n",
    "\n",
    "\n",
    "class RunningAverage(AverageBase):\n",
    "    \"\"\"\n",
    "    Keeps track of a cumulative moving average (CMA).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, value=0, count=0):\n",
    "        super(RunningAverage, self).__init__(value)\n",
    "        self.count = count\n",
    "\n",
    "    def update(self, value):\n",
    "        self.value = self.value * self.count + float(value)\n",
    "        self.count += 1\n",
    "        self.value /= self.count\n",
    "        return self.value\n",
    "\n",
    "\n",
    "class MovingAverage(AverageBase):\n",
    "    \"\"\"\n",
    "    An exponentially decaying moving average (EMA).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, alpha=0.99):\n",
    "        super(MovingAverage, self).__init__(None)\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def update(self, value):\n",
    "        if self.value is None:\n",
    "            self.value = float(value)\n",
    "        else:\n",
    "            self.value = self.alpha * self.value + (1 - self.alpha) * float(value)\n",
    "        return self.value\n",
    "\n",
    "\n",
    "def labels_to_class(pred_labels):\n",
    "    predictions = []\n",
    "    for i in range(pred_labels.shape[0]):\n",
    "        curr_labels = pred_labels[i, :].cpu().detach().numpy()\n",
    "        best_dist = sys.maxsize\n",
    "        best_index = -1\n",
    "        for j in range(predicates.shape[0]):\n",
    "            class_labels = predicates[j, :]\n",
    "            dist = get_euclidean_dist(curr_labels, class_labels)\n",
    "            if dist < best_dist and classes[j] not in train_classes:\n",
    "                best_index = j\n",
    "                best_dist = dist\n",
    "        predictions.append(classes[best_index])\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def get_hamming_dist(curr_labels, class_labels):\n",
    "    return np.sum(curr_labels != class_labels)\n",
    "\n",
    "\n",
    "def get_cosine_dist(curr_labels, class_labels):\n",
    "    return (\n",
    "        np.sum(curr_labels * class_labels)\n",
    "        / np.sqrt(np.sum(curr_labels))\n",
    "        / np.sqrt(np.sum(class_labels))\n",
    "    )\n",
    "\n",
    "\n",
    "def get_euclidean_dist(curr_labels, class_labels):\n",
    "    return np.sqrt(np.sum((curr_labels - class_labels) ** 2))\n",
    "\n",
    "\n",
    "def save_checkpoint(optimizer, model, epoch, filename):\n",
    "    checkpoint_dict = {\n",
    "        \"optimizer\": optimizer.state_dict(),\n",
    "        \"model\": model.state_dict(),\n",
    "        \"epoch\": epoch,\n",
    "    }\n",
    "    torch.save(checkpoint_dict, filename)\n",
    "\n",
    "\n",
    "def load_checkpoint(optimizer, model, filename):\n",
    "    checkpoint_dict = torch.load(filename)\n",
    "    epoch = checkpoint_dict[\"epoch\"]\n",
    "    model.load_state_dict(checkpoint_dict[\"model\"])\n",
    "    if optimizer is not None:\n",
    "        optimizer.load_state_dict(checkpoint_dict[\"optimizer\"])\n",
    "    return epoch\n",
    "\n",
    "\n",
    "class ProgressMonitor(object):\n",
    "    \"\"\"\n",
    "    Custom IPython progress bar for training\n",
    "    \"\"\"\n",
    "\n",
    "    tmpl = \"\"\"\n",
    "        <p>Loss: {loss:0.4f}   {value} / {length}</p>\n",
    "        <progress value='{value}' max='{length}', style='width: 100%'>{value}</progress>\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, length):\n",
    "        self.length = length\n",
    "        self.count = 0\n",
    "        self.display = display(self.html(0, 0), display_id=True)\n",
    "\n",
    "    def html(self, count, loss):\n",
    "        return HTML(self.tmpl.format(length=self.length, value=count, loss=loss))\n",
    "\n",
    "    def update(self, count, loss):\n",
    "        self.count += count\n",
    "        self.display.update(self.html(self.count, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint_extra_details(\n",
    "    epoch, train_losses, valid_losses, mean_acc, filename\n",
    "):\n",
    "    checkpoint_dict = {\n",
    "        \"epoch\": epoch,\n",
    "        \"train_losses\": train_losses,\n",
    "        \"valid_losses\": valid_losses,\n",
    "        \"mean_acc\": mean_acc,\n",
    "    }\n",
    "    torch.save(checkpoint_dict, filename)\n",
    "\n",
    "\n",
    "def load_checkpoint_extra_details(filename):\n",
    "    checkpoint_dict = torch.load(filename)\n",
    "    epoch = checkpoint_dict[\"epoch\"]\n",
    "    train_losses = checkpoint_dict[\"train_losses\"]\n",
    "    valid_losses = checkpoint_dict[\"valid_losses\"]\n",
    "    mean_acc = checkpoint_dict[\"mean_acc\"]\n",
    "    return epoch, train_losses, valid_losses, mean_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file checkpoints already exists.\n"
     ]
    }
   ],
   "source": [
    "!mkdir checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, num_epochs=25, first_epoch=1):\n",
    "    criterion = nn.BCELoss()  # should be loss function defined above\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    y_pred = []\n",
    "    total_steps = len(train_loader)\n",
    "    for epoch in range(first_epoch, first_epoch + num_epochs):\n",
    "        print(\"Epoch\", epoch)\n",
    "        progress = ProgressMonitor(length=len(train_dataset))\n",
    "        train_loss = MovingAverage()\n",
    "        model.train()\n",
    "        for i, (images, labels, indexes, predicates_mats) in enumerate(train_loader):\n",
    "            if images.shape[0] < 2:\n",
    "                break\n",
    "            images = images.to(device)\n",
    "            predicates_mats = predicates_mats.to(device).float()\n",
    "            outputs = model(images)\n",
    "            predicted_outputs = torch.sigmoid(outputs)  # should be softmax\n",
    "            loss = criterion(predicted_outputs, predicates_mats)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss.update(loss)\n",
    "            progress.update(images.shape[0], train_loss)\n",
    "        #             print(\n",
    "        #                 \"Epoch [{}/{}], Step [{}/{}], Batch Loss: {:.4f}\".format(\n",
    "        #                     epoch, num_epochs, i + 1, total_steps, loss.item()\n",
    "        #                 )\n",
    "        #             )\n",
    "\n",
    "        print(\"Training loss:\", train_loss)\n",
    "        train_losses.append(train_loss.value)\n",
    "\n",
    "        model.eval()\n",
    "        valid_loss = RunningAverage()\n",
    "        y_pred.clear()\n",
    "\n",
    "        pred_classes = []\n",
    "        truth_classes = []\n",
    "        mean_acc = 0.0\n",
    "        with torch.no_grad():\n",
    "            for i, (images, labels, indexes, predicates_mats) in enumerate(test_loader):\n",
    "                images = images.to(device)\n",
    "                predicates_mats = predicates_mats.to(device).float()\n",
    "                outputs = model(images)\n",
    "                predicted_outputs = torch.sigmoid(outputs)  # should be softmax\n",
    "                loss = criterion(predicted_outputs, predicates_mats)\n",
    "                valid_loss.update(loss)\n",
    "                curr_pred_classes = labels_to_class(predicted_outputs)\n",
    "                pred_classes.extend(curr_pred_classes)\n",
    "                curr_truth_classes = []\n",
    "                for index in labels:\n",
    "                    curr_truth_classes.append(classes[index])\n",
    "                truth_classes.extend(curr_truth_classes)\n",
    "        pred_classes = np.array(pred_classes)\n",
    "        truth_classes = np.array(truth_classes)\n",
    "        mean_acc = np.mean(pred_classes == truth_classes)\n",
    "        print(\"Validation loss:\", valid_loss)\n",
    "        valid_losses.append(valid_loss.value)\n",
    "        print(\"Validation accuracy: {:.4f}%\".format(mean_acc * 100))\n",
    "\n",
    "        checkpoint_filename = \"checkpoints/awa2-{:03d}.pkl\".format(epoch)\n",
    "        save_checkpoint(optimizer, model, epoch, checkpoint_filename)\n",
    "        checkpoint_filename = \"checkpoints/awa2-extra-{:03d}.pkl\".format(epoch)\n",
    "        save_checkpoint_extra_details(\n",
    "            epoch, train_losses, valid_losses, mean_acc, checkpoint_filename\n",
    "        )\n",
    "    return train_losses, valid_losses, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <p>Loss: 0.4046   30336 / 30337</p>\n",
       "        <progress value='30336' max='30337', style='width: 100%'>30336</progress>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.4046\n",
      "Validation loss: 0.5511\n",
      "Validation accuracy: 25.5261%\n",
      "Epoch 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <p>Loss: 0.3235   30336 / 30337</p>\n",
       "        <progress value='30336' max='30337', style='width: 100%'>30336</progress>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.3235\n",
      "Validation loss: 0.5273\n",
      "Validation accuracy: 31.6106%\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.000025)\n",
    "train_losses, valid_losses, y_pred = train(model, optimizer, num_epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive F is New Volume\n",
      " Volume Serial Number is E67B-CFF0\n",
      "\n",
      " Directory of F:\\JupyterDefault\\PyTorch\\checkpoints\n",
      "\n",
      "04/09/2020  12:32 PM    <DIR>          .\n",
      "04/09/2020  12:32 PM    <DIR>          ..\n",
      "04/09/2020  11:54 AM        85,788,520 awa2-001.pkl\n",
      "04/09/2020  12:32 PM        85,788,520 awa2-002.pkl\n",
      "               2 File(s)    171,577,040 bytes\n",
      "               2 Dir(s)  240,845,008,896 bytes free\n"
     ]
    }
   ],
   "source": [
    "!dir checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming training from epoch 3\n",
      "Epoch 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <p>Loss: 0.2489   30336 / 30337</p>\n",
       "        <progress value='30336' max='30337', style='width: 100%'>30336</progress>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.2489\n",
      "Validation loss: 0.5071\n",
      "Validation accuracy: 43.1353%\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'save_checkpoint_extra_details' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-f51e9cf924e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'checkpoints/awa2-002.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Resuming training from epoch'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtrain_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfirst_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-27-f2328313703b>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, optimizer, num_epochs, first_epoch)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0msave_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckpoint_filename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[0mcheckpoint_filename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"checkpoints/awa2-extra-{:03d}.pkl\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[0msave_checkpoint_extra_details\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckpoint_filename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'save_checkpoint_extra_details' is not defined"
     ]
    }
   ],
   "source": [
    "epoch = load_checkpoint(optimizer, model, \"checkpoints/awa2-002.pkl\")\n",
    "print(\"Resuming training from epoch\", epoch + 1)\n",
    "train_losses, valid_losses, y_pred = train(\n",
    "    model, optimizer, num_epochs=1, first_epoch=epoch + 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = range(1, len(train_losses) + 1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, train_losses, \"-o\", label=\"Training loss\")\n",
    "plt.plot(epochs, valid_losses, \"-o\", label=\"Validation loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Learning curves\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xticks(epochs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'bool' object has no attribute 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-d93d50e51107>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnum_errors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_class_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Validation errors {} (out of {})\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_errors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'bool' object has no attribute 'int'"
     ]
    }
   ],
   "source": [
    "num_errors = torch.sum((y_pred != test_dataset.image_class_index).float())\n",
    "print(\"Validation errors {} (out of {})\".format(int(num_errors), len(test_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, dataloader):\n",
    "    # Toggle flag\n",
    "    model.eval()\n",
    "\n",
    "    pred_classes = []\n",
    "    #     output_img_names = []\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels, indexes, predicates_mats) in enumerate(dataloader):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            sigmoid_outputs = torch.sigmoid(outputs)\n",
    "            pred_labels = sigmoid_outputs  # (sigmoid_outputs > 0.5).int()\n",
    "            curr_pred_classes = labels_to_class(pred_labels)\n",
    "            pred_classes.extend(curr_pred_classes)\n",
    "    #             output_img_names.extend(img_names)\n",
    "\n",
    "    return pred_classes\n",
    "\n",
    "\n",
    "predict(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_env]",
   "language": "python",
   "name": "conda-env-pytorch_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
