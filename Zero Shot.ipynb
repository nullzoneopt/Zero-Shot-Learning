{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AWA2(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        classes_file,\n",
    "        transform=None,\n",
    "        path_prefix=\"data\",\n",
    "        predicate_binary_mask=True,\n",
    "    ):\n",
    "        self.transform = transform\n",
    "\n",
    "        if predicate_binary_mask:\n",
    "            self.predicates_mat = np.genfromtxt(\n",
    "                os.path.join(path_prefix, \"predicate-matrix-binary.txt\"), dtype=\"float\"\n",
    "            )\n",
    "        else:\n",
    "            self.predicates_mat = np.genfromtxt(\n",
    "                os.path.join(path_prefix, \"predicate-matrix-continuous.txt\"),\n",
    "                dtype=\"float\",\n",
    "            )\n",
    "\n",
    "        self.classes_dict = {}\n",
    "        classes_array = np.genfromtxt(\n",
    "            os.path.join(path_prefix, \"classes.txt\"), dtype=\"str\"\n",
    "        )\n",
    "        for row in classes_array:\n",
    "            self.classes_dict[row[1]] = int(row[0]) - 1\n",
    "        image_names = []\n",
    "        image_class_index = []\n",
    "\n",
    "        self.classes = []\n",
    "        with open(os.path.join(path_prefix, classes_file)) as f:\n",
    "            for line in f:\n",
    "                class_name = line.strip()\n",
    "                self.classes.append(class_name)\n",
    "                images = glob(\n",
    "                    os.path.join(path_prefix, \"JPEGImages\", class_name, \"*.jpg\")\n",
    "                )\n",
    "\n",
    "                class_index = self.classes_dict[class_name]\n",
    "                for image in images:\n",
    "                    image_names.append(image)\n",
    "                    image_class_index.append(class_index)\n",
    "\n",
    "        self.image_names = image_names\n",
    "        self.image_class_index = image_class_index\n",
    "        self.len = len(self.image_names)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.image_names[index])\n",
    "        #         print(image.shape)\n",
    "        if image.getbands()[0] == \"L\":\n",
    "            image = image.convert(\"RGB\")\n",
    "        #         if image.shape != (3,224,224):\n",
    "        #             print(self.image_class_index[index])\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        class_index = self.image_class_index[index]\n",
    "        image_predicate = self.predicates_mat[class_index, :]\n",
    "        return image, class_index, self.image_names[index], image_predicate\n",
    "\n",
    "    def display_sample(self, n=1):\n",
    "        for i in range(n):\n",
    "            plt.imshow(self.__getitem__(i)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transformers = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(brightness=0.3, contrast=0.3),\n",
    "        transforms.Resize((224, 224)),  # ImageNet standard\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_transformers = transforms.Compose(\n",
    "    [transforms.Resize((224, 224)), transforms.ToTensor()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = AWA2(\n",
    "    classes_file=\"testclasses.txt\", path_prefix=\"data1\", transform=train_transformers\n",
    ")\n",
    "train_dataset = AWA2(\n",
    "    classes_file=\"trainclasses.txt\", path_prefix=\"data1\", transform=test_transformers\n",
    ")\n",
    "len(train_dataset.classes), len(test_dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {\"batch_size\": 24, \"shuffle\": True, \"num_workers\": 0}\n",
    "test_params = {\"batch_size\": 1, \"shuffle\": True, \"num_workers\": 0}\n",
    "train_loader = DataLoader(train_dataset, **train_params)\n",
    "test_loader = DataLoader(test_dataset, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50, 85), 50, 50, 40)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predicates_ground_truth(\n",
    "    path_prefix=\"data\", predicate_binary_mask=True, train_classes=\"trainclasses.txt\"\n",
    "):\n",
    "    predicates_mat = None\n",
    "    if predicate_binary_mask:\n",
    "        predicates_mat = np.genfromtxt(\n",
    "            os.path.join(path_prefix, \"predicate-matrix-binary.txt\"), dtype=\"float\"\n",
    "        )\n",
    "    else:\n",
    "        predicates_mat = np.genfromtxt(\n",
    "            os.path.join(path_prefix, \"predicate-matrix-continuous.txt\"), dtype=\"float\",\n",
    "        )\n",
    "    classes_array = np.genfromtxt(\n",
    "        os.path.join(path_prefix, \"classes.txt\"), dtype=\"str\"\n",
    "    )[:, -1]\n",
    "    train_classes = np.genfromtxt(os.path.join(path_prefix, train_classes), dtype=\"str\")\n",
    "    return predicates_mat, len(predicates_mat), classes_array, train_classes\n",
    "\n",
    "\n",
    "predicates, num_predicates, classes, train_classes = predicates_ground_truth(\n",
    "    path_prefix=\"data1\"\n",
    ")\n",
    "predicates.shape, num_predicates, len(classes), len(train_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(is_pretrained=True, resnet=\"resnet34\", num_predicates=85):\n",
    "    model = None\n",
    "    if resnet == \"resnet18\":\n",
    "        model = torchvision.models.resnet18(pretrained=is_pretrained)\n",
    "    elif resnet == \"resnet50\":\n",
    "        model = torchvision.models.resnet50(pretrained=is_pretrained)\n",
    "    else:\n",
    "        model = torchvision.models.resnet34(pretrained=is_pretrained)\n",
    "    if is_pretrained:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.BatchNorm1d(num_features),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.25),\n",
    "        nn.Linear(num_features, num_predicates),\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Sequential(\n",
       "   (0): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (1): ReLU()\n",
       "   (2): Dropout(p=0.25, inplace=False)\n",
       "   (3): Linear(in_features=512, out_features=85, bias=True)\n",
       " ),\n",
       " True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model().to(device)\n",
    "model.fc, next(model.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COPIED CONTENT\n",
    "def cos_loss(input, target):\n",
    "    return 1 - F.cosine_similarity(input, target).mean()\n",
    "\n",
    "\n",
    "class AverageBase(object):\n",
    "    def __init__(self, value=0):\n",
    "        self.value = float(value) if value is not None else None\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(round(self.value, 4))\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.value\n",
    "\n",
    "    def __format__(self, fmt):\n",
    "        return self.value.__format__(fmt)\n",
    "\n",
    "    def __float__(self):\n",
    "        return self.value\n",
    "\n",
    "\n",
    "class RunningAverage(AverageBase):\n",
    "    \"\"\"\n",
    "    Keeps track of a cumulative moving average (CMA).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, value=0, count=0):\n",
    "        super(RunningAverage, self).__init__(value)\n",
    "        self.count = count\n",
    "\n",
    "    def update(self, value):\n",
    "        self.value = self.value * self.count + float(value)\n",
    "        self.count += 1\n",
    "        self.value /= self.count\n",
    "        return self.value\n",
    "\n",
    "\n",
    "class MovingAverage(AverageBase):\n",
    "    \"\"\"\n",
    "    An exponentially decaying moving average (EMA).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, alpha=0.99):\n",
    "        super(MovingAverage, self).__init__(None)\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def update(self, value):\n",
    "        if self.value is None:\n",
    "            self.value = float(value)\n",
    "        else:\n",
    "            self.value = self.alpha * self.value + (1 - self.alpha) * float(value)\n",
    "        return self.value\n",
    "\n",
    "\n",
    "def labels_to_class(pred_labels):\n",
    "    predictions = []\n",
    "    for i in range(pred_labels.shape[0]):\n",
    "        curr_labels = pred_labels[i, :].cpu().detach().numpy()\n",
    "        best_dist = sys.maxsize\n",
    "        best_index = -1\n",
    "        for j in range(predicates.shape[0]):\n",
    "            class_labels = predicates[j, :]\n",
    "            dist = get_euclidean_dist(curr_labels, class_labels)\n",
    "            if dist < best_dist and classes[j] not in train_classes:\n",
    "                best_index = j\n",
    "                best_dist = dist\n",
    "        predictions.append(classes[best_index])\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def get_hamming_dist(curr_labels, class_labels):\n",
    "    return np.sum(curr_labels != class_labels)\n",
    "\n",
    "\n",
    "def get_cosine_dist(curr_labels, class_labels):\n",
    "    return (\n",
    "        np.sum(curr_labels * class_labels)\n",
    "        / np.sqrt(np.sum(curr_labels))\n",
    "        / np.sqrt(np.sum(class_labels))\n",
    "    )\n",
    "\n",
    "\n",
    "def get_euclidean_dist(curr_labels, class_labels):\n",
    "    return np.sqrt(np.sum((curr_labels - class_labels) ** 2))\n",
    "\n",
    "\n",
    "def save_checkpoint(optimizer, model, epoch, filename):\n",
    "    checkpoint_dict = {\n",
    "        \"optimizer\": optimizer.state_dict(),\n",
    "        \"model\": model.state_dict(),\n",
    "        \"epoch\": epoch,\n",
    "    }\n",
    "    torch.save(checkpoint_dict, filename)\n",
    "\n",
    "\n",
    "def load_checkpoint(optimizer, model, filename):\n",
    "    checkpoint_dict = torch.load(filename)\n",
    "    epoch = checkpoint_dict[\"epoch\"]\n",
    "    model.load_state_dict(checkpoint_dict[\"model\"])\n",
    "    if optimizer is not None:\n",
    "        optimizer.load_state_dict(checkpoint_dict[\"optimizer\"])\n",
    "    return epoch\n",
    "\n",
    "\n",
    "class ProgressMonitor(object):\n",
    "    \"\"\"\n",
    "    Custom IPython progress bar for training\n",
    "    \"\"\"\n",
    "\n",
    "    tmpl = \"\"\"\n",
    "        <p>Loss: {loss:0.4f}   {value} / {length}</p>\n",
    "        <progress value='{value}' max='{length}', style='width: 100%'>{value}</progress>\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, length):\n",
    "        self.length = length\n",
    "        self.count = 0\n",
    "        self.display = display(self.html(0, 0), display_id=True)\n",
    "\n",
    "    def html(self, count, loss):\n",
    "        return HTML(self.tmpl.format(length=self.length, value=count, loss=loss))\n",
    "\n",
    "    def update(self, count, loss):\n",
    "        self.count += count\n",
    "        self.display.update(self.html(self.count, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint_extra_details(\n",
    "    epoch, train_losses, valid_losses, mean_acc, filename\n",
    "):\n",
    "    checkpoint_dict = {\n",
    "        \"epoch\": epoch,\n",
    "        \"train_losses\": train_losses,\n",
    "        \"valid_losses\": valid_losses,\n",
    "        \"mean_acc\": mean_acc,\n",
    "    }\n",
    "    torch.save(checkpoint_dict, filename)\n",
    "\n",
    "\n",
    "def load_checkpoint_extra_details(filename):\n",
    "    checkpoint_dict = torch.load(filename)\n",
    "    epoch = checkpoint_dict[\"epoch\"]\n",
    "    train_losses = checkpoint_dict[\"train_losses\"]\n",
    "    valid_losses = checkpoint_dict[\"valid_losses\"]\n",
    "    mean_acc = checkpoint_dict[\"mean_acc\"]\n",
    "    return epoch, train_losses, valid_losses, mean_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file checkpoints already exists.\n"
     ]
    }
   ],
   "source": [
    "!mkdir checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, num_epochs=25, first_epoch=1):\n",
    "    criterion = nn.BCELoss()  # should be loss function defined above\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    total_steps = len(train_loader)\n",
    "    for epoch in range(first_epoch, first_epoch + num_epochs):\n",
    "        print(\"Epoch\", epoch)\n",
    "        progress = ProgressMonitor(length=len(train_dataset))\n",
    "        train_loss = MovingAverage()\n",
    "        model.train()\n",
    "        for i, (images, labels, indexes, predicates_mats) in enumerate(train_loader):\n",
    "            if images.shape[0] < 2:\n",
    "                break\n",
    "            images = images.to(device)\n",
    "            predicates_mats = predicates_mats.to(device).float()\n",
    "            outputs = model(images)\n",
    "            predicted_outputs = torch.sigmoid(outputs)  # should be softmax\n",
    "            loss = criterion(predicted_outputs, predicates_mats)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss.update(loss)\n",
    "            progress.update(images.shape[0], train_loss)\n",
    "        #             print(\n",
    "        #                 \"Epoch [{}/{}], Step [{}/{}], Batch Loss: {:.4f}\".format(\n",
    "        #                     epoch, num_epochs, i + 1, total_steps, loss.item()\n",
    "        #                 )\n",
    "        #             )\n",
    "\n",
    "        print(\"Training loss:\", train_loss)\n",
    "        train_losses.append(train_loss.value)\n",
    "\n",
    "        model.eval()\n",
    "        valid_loss = RunningAverage()\n",
    "\n",
    "        pred_classes = []\n",
    "        truth_classes = []\n",
    "        mean_acc = 0.0\n",
    "        with torch.no_grad():\n",
    "            for i, (images, labels, indexes, predicates_mats) in enumerate(test_loader):\n",
    "                images = images.to(device)\n",
    "                predicates_mats = predicates_mats.to(device).float()\n",
    "                outputs = model(images)\n",
    "                predicted_outputs = torch.sigmoid(outputs)  # should be softmax\n",
    "                loss = criterion(predicted_outputs, predicates_mats)\n",
    "                valid_loss.update(loss)\n",
    "                curr_pred_classes = labels_to_class(predicted_outputs)\n",
    "                pred_classes.extend(curr_pred_classes)\n",
    "                curr_truth_classes = []\n",
    "                for index in labels:\n",
    "                    curr_truth_classes.append(classes[index])\n",
    "                truth_classes.extend(curr_truth_classes)\n",
    "        pred_classes = np.array(pred_classes)\n",
    "        truth_classes = np.array(truth_classes)\n",
    "        mean_acc = np.mean(pred_classes == truth_classes)\n",
    "        print(\"Validation loss:\", valid_loss)\n",
    "        valid_losses.append(valid_loss.value)\n",
    "        print(\"Validation accuracy: {:.4f}%\".format(mean_acc * 100))\n",
    "\n",
    "        checkpoint_filename = \"checkpoints/awa2-{:03d}.pkl\".format(epoch)\n",
    "        save_checkpoint(optimizer, model, epoch, checkpoint_filename)\n",
    "        checkpoint_filename = \"checkpoints/awa2-extra-{:03d}.pkl\".format(epoch)\n",
    "        save_checkpoint_extra_details(\n",
    "            epoch, train_losses, valid_losses, mean_acc, checkpoint_filename\n",
    "        )\n",
    "    return train_losses, valid_losses, pred_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <p>Loss: 0.4046   30336 / 30337</p>\n",
       "        <progress value='30336' max='30337', style='width: 100%'>30336</progress>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.4046\n",
      "Validation loss: 0.5511\n",
      "Validation accuracy: 25.5261%\n",
      "Epoch 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <p>Loss: 0.3235   30336 / 30337</p>\n",
       "        <progress value='30336' max='30337', style='width: 100%'>30336</progress>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.3235\n",
      "Validation loss: 0.5273\n",
      "Validation accuracy: 31.6106%\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.000025)\n",
    "train_losses, valid_losses, y_pred = train(model, optimizer, num_epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive F is New Volume\n",
      " Volume Serial Number is E67B-CFF0\n",
      "\n",
      " Directory of F:\\JupyterDefault\\PyTorch\\checkpoints\n",
      "\n",
      "04/09/2020  08:10 PM    <DIR>          .\n",
      "04/09/2020  08:10 PM    <DIR>          ..\n",
      "04/09/2020  11:54 AM        85,788,520 awa2-001.pkl\n",
      "04/09/2020  01:19 PM        85,788,520 awa2-002.pkl\n",
      "04/09/2020  02:15 PM        85,788,520 awa2-003.pkl\n",
      "04/09/2020  08:10 PM        85,788,520 awa2-004.pkl\n",
      "04/09/2020  08:10 PM               402 awa2-extra-004.pkl\n",
      "               5 File(s)    343,154,482 bytes\n",
      "               2 Dir(s)  238,447,849,472 bytes free\n"
     ]
    }
   ],
   "source": [
    "!dir checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming training from epoch 5\n",
      "Epoch 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <p>Loss: 0.2197   30336 / 30337</p>\n",
       "        <progress value='30336' max='30337', style='width: 100%'>30336</progress>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.2197\n",
      "Validation loss: 0.5203\n",
      "Validation accuracy: 46.6858%\n",
      "Epoch 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <p>Loss: 0.2062   30336 / 30337</p>\n",
       "        <progress value='30336' max='30337', style='width: 100%'>30336</progress>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.2062\n",
      "Validation loss: 0.5242\n",
      "Validation accuracy: 49.4345%\n",
      "Epoch 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <p>Loss: 0.1958   30336 / 30337</p>\n",
       "        <progress value='30336' max='30337', style='width: 100%'>30336</progress>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.1958\n",
      "Validation loss: 0.5312\n",
      "Validation accuracy: 50.3078%\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.000025)\n",
    "epoch = load_checkpoint(optimizer, model, \"checkpoints/awa2-004.pkl\")\n",
    "print(\"Resuming training from epoch\", epoch + 1)\n",
    "train_losses, valid_losses, y_pred = train(\n",
    "    model, optimizer, num_epochs=3, first_epoch=epoch + 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = range(1, len(train_losses) + 1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, train_losses, \"-o\", label=\"Training loss\")\n",
    "plt.plot(epochs, valid_losses, \"-o\", label=\"Validation loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Learning curves\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xticks(epochs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation errors 6225 (out of 6985)\n"
     ]
    }
   ],
   "source": [
    "num_errors = np.sum(y_pred != classes[test_dataset.image_class_index])\n",
    "print(\"Validation errors {} (out of {})\".format(int(num_errors), len(test_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, dataloader):\n",
    "    # Toggle flag\n",
    "    model.eval()\n",
    "\n",
    "    pred_classes = []\n",
    "    truth_classes = []\n",
    "    correct = 0\n",
    "    #     output_img_names = []\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels, indexes, predicates_mats) in enumerate(dataloader):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            sigmoid_outputs = torch.sigmoid(outputs)\n",
    "            pred_labels = sigmoid_outputs  # (sigmoid_outputs > 0.5).int()\n",
    "            curr_pred_classes = labels_to_class(pred_labels)\n",
    "            pred_classes.extend(curr_pred_classes)\n",
    "            curr_truth_classes = []\n",
    "            for index in labels:\n",
    "                curr_truth_classes.append(classes[index])\n",
    "            truth_classes.extend(curr_truth_classes)\n",
    "        pred_classes = np.array(pred_classes)\n",
    "        truth_classes = np.array(truth_classes)\n",
    "\n",
    "    return pred_classes, truth_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted, truth_classes = predict(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3451"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_predicted != truth_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "687"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_predicted == classes[test_dataset.image_class_index])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_env]",
   "language": "python",
   "name": "conda-env-pytorch_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
